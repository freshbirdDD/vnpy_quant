"""
import_cffex_minute_bars_v4.py
vn.py 4.2ç‰ˆæœ¬ - å°†åŒ…å«å¤šä¸ªCFFEXåˆçº¦çš„åˆ†é’ŸBaræ•°æ®CSVå¯¼å…¥æ•°æ®åº“

CSVæ ¼å¼è¦æ±‚ï¼š
    æ—¶é—´,å¼€ç›˜ä»·,æœ€é«˜ä»·,æœ€ä½ä»·,æ”¶ç›˜ä»·,æˆäº¤é‡,æˆäº¤é¢,æŒä»“é‡,åˆçº¦ä»£ç 
ç¤ºä¾‹ï¼š
    2024-01-02 09:30:00,3439.4,3440.2,3439.0,3440.0,1000,3440000,105704,IF1005
"""
import pandas as pd
import numpy as np
from datetime import datetime, time
from pathlib import Path
from typing import List, Dict, Set, Optional
from vnpy.trader.constant import Exchange, Interval
from vnpy.trader.object import BarData
from vnpy.trader.database import BaseDatabase, get_database


class CFFEXMinuteBarImporter:
    """CFFEXäº¤æ˜“æ‰€å¤šåˆçº¦åˆ†é’ŸBaræ•°æ®å¯¼å…¥å™¨ (vn.py 4.2ç‰ˆæœ¬)"""

    # ToDo å¿…å¡«å­—æ®µæ˜ å°„ï¼Œå¦‚æœåç»­å¯¼å…¥æ•°æ®çš„å­—æ®µåæœ‰ä¿®æ”¹ï¼Œéœ€è¦åœ¨è¿™é‡ŒåŒæ­¥
    REQUIRED_FIELDS = {
        'æ—¶é—´': 'datetime_str',
        'å¼€ç›˜ä»·': 'open_price',
        'æœ€é«˜ä»·': 'high_price',
        'æœ€ä½ä»·': 'low_price',
        'æ”¶ç›˜ä»·': 'close_price',
        'æˆäº¤é‡': 'volume',
        'æˆäº¤é¢': 'turnover',
        'æŒä»“é‡': 'open_interest',
        'åˆçº¦ä»£ç ': 'symbol'
    }

    def __init__(self, file_path: str):
        """
        åˆå§‹åŒ–å¯¼å…¥å™¨

        Args:
            file_path: CSVæ–‡ä»¶è·¯å¾„
        """
        self.file_path = Path(file_path)
        if not self.file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")

        self.exchange = Exchange.CFFEX
        self.interval = Interval.MINUTE
        self.gateway_name = "CSV_IMPORT"
        self.database: BaseDatabase = get_database()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_rows': 0,
            'valid_rows': 0,
            'invalid_rows': 0,
            'unique_symbols': set(),
            'time_range': {'start': None, 'end': None},
            'saved_bars': 0
        }

    def parse_datetime(self, dt_str: str) -> Optional[datetime]:
        """
        è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡
        æ”¯æŒå¤šç§æ ¼å¼ï¼š'2024-01-02 09:30:00' æˆ– '2024/01/02 09:30:00'ç­‰
        """
        if pd.isna(dt_str) or not isinstance(dt_str, str):
            return None

        dt_str = str(dt_str).strip()
        if not dt_str:
            return None

        # å°è¯•å¤šç§æ—¶é—´æ ¼å¼
        date_formats = [
            '%Y-%m-%d %H:%M:%S',
            '%Y/%m/%d %H:%M:%S',
            '%Y%m%d %H:%M:%S',
            '%Y-%m-%d %H:%M',
            '%Y/%m/%d %H:%M',
            '%Y%m%d %H:%M',
        ]

        for fmt in date_formats:
            try:
                dt = datetime.strptime(dt_str, fmt)
                # ç¡®ä¿ç§’æ•°ä¸º0ï¼ˆåˆ†é’Ÿæ•°æ®ç‰¹æ€§ï¼‰
                if dt.second != 0:
                    dt = dt.replace(second=0)
                return dt
            except ValueError:
                continue

        # å¦‚æœéƒ½ä¸æˆåŠŸï¼Œå°è¯•åªè§£ææ—¥æœŸéƒ¨åˆ†
        try:
            # åªå–æ—¥æœŸéƒ¨åˆ†ï¼Œæ—¶é—´è®¾ä¸º9:30ï¼ˆäº¤æ˜“æ—¥å¼€å§‹ï¼‰
            date_part = dt_str.split()[0]
            dt = datetime.strptime(date_part, '%Y-%m-%d')
            return dt.replace(hour=9, minute=30, second=0)
        except:
            return None

    def validate_symbol(self, symbol: str) -> Optional[str]:
        """
        éªŒè¯å¹¶æ¸…ç†åˆçº¦ä»£ç 
        æ”¯æŒï¼šIF1005, IF888, IF.CFFEX ç­‰æ ¼å¼
        """
        if pd.isna(symbol) or not isinstance(symbol, str):
            return None

        symbol = str(symbol).strip().upper()

        # ç§»é™¤å¯èƒ½åŒ…å«çš„äº¤æ˜“æ‰€åç¼€
        if '.' in symbol:
            parts = symbol.split('.')
            symbol = parts[0]  # å–ç¬¬ä¸€ä¸ªéƒ¨åˆ†ä½œä¸ºåˆçº¦ä»£ç 

        # éªŒè¯åŸºæœ¬æ ¼å¼ï¼ˆè‡³å°‘2ä¸ªå­—æ¯+æ•°å­—ï¼‰
        if len(symbol) >= 2 and symbol[:2].isalpha():
            return symbol
        return None

    def parse_row_to_bar(self, row: pd.Series, index: int) -> Optional[BarData]:
        """
        å°†ä¸€è¡Œæ•°æ®è§£æä¸ºBarDataå¯¹è±¡ (vn.py 4.2ç‰ˆæœ¬)
        """
        try:
            # 1. è§£æåˆçº¦ä»£ç 
            raw_symbol = row.get('åˆçº¦ä»£ç ')
            symbol = self.validate_symbol(raw_symbol)
            if not symbol:
                print(f"è¡Œ {index}: æ— æ•ˆçš„åˆçº¦ä»£ç  '{raw_symbol}'")
                return None

            # 2. è§£ææ—¶é—´
            raw_time = row.get('æ—¶é—´')
            dt = self.parse_datetime(raw_time)
            if not dt:
                print(f"è¡Œ {index}: æ— æ•ˆçš„æ—¶é—´æ ¼å¼ '{raw_time}'")
                return None

            # 3. è§£æä»·æ ¼å’Œæˆäº¤é‡ï¼ˆå¿…éœ€å­—æ®µï¼‰
            # TODO è¿™é‡Œçš„é£é™©åœ¨äºï¼Œå¦‚æœè¿™è¡Œçš„è¯¥å­—æ®µç¼ºå¤±ï¼Œä¼šé™é»˜åœ°å¡«æˆ0
            try:
                open_price = float(row.get('å¼€ç›˜ä»·', 0))
                high_price = float(row.get('æœ€é«˜ä»·', 0))
                low_price = float(row.get('æœ€ä½ä»·', 0))
                close_price = float(row.get('æ”¶ç›˜ä»·', 0))
                volume = float(row.get('æˆäº¤é‡', 0))
            except (ValueError, TypeError) as e:
                print(f"è¡Œ {index}: æ•°å€¼è½¬æ¢é”™è¯¯: {e}")
                return None

            # 4. è§£æå¯é€‰å­—æ®µ
            turnover = 0.0
            open_interest = 0.0

            if 'æˆäº¤é¢' in row and pd.notna(row['æˆäº¤é¢']):
                try:
                    turnover = float(row['æˆäº¤é¢'])
                except:
                    turnover = volume * close_price  # ä¼°ç®—æˆäº¤é¢

            if 'æŒä»“é‡' in row and pd.notna(row['æŒä»“é‡']):
                try:
                    open_interest = float(row['æŒä»“é‡'])
                except:
                    open_interest = 0.0

            # 5. åˆ›å»ºBarDataå¯¹è±¡ (vn.py 4.2ç‰ˆæœ¬)
            # æ³¨æ„ï¼švn.py 4.2çš„BarDataæ„é€ å‡½æ•°å‚æ•°
            bar = BarData(
                gateway_name=self.gateway_name,
                symbol=symbol,
                exchange=self.exchange,
                datetime=dt,
                interval=self.interval,
                volume=volume,
                turnover=turnover,
                open_interest=open_interest,
                open_price=open_price,
                high_price=high_price,
                low_price=low_price,
                close_price=close_price,
            )

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats['valid_rows'] += 1
            self.stats['unique_symbols'].add(symbol)

            if not self.stats['time_range']['start'] or dt < self.stats['time_range']['start']:
                self.stats['time_range']['start'] = dt
            if not self.stats['time_range']['end'] or dt > self.stats['time_range']['end']:
                self.stats['time_range']['end'] = dt

            return bar

        except Exception as e:
            print(f"è¡Œ {index}: è§£æé”™è¯¯: {e}")
            self.stats['invalid_rows'] += 1
            return None

    def load_and_validate_csv(self) -> pd.DataFrame:
        """
        åŠ è½½CSVæ–‡ä»¶å¹¶è¿›è¡ŒåŸºæœ¬éªŒè¯
        """
        print(f"åŠ è½½CSVæ–‡ä»¶: {self.file_path}")

        try:
            # è¯»å–CSVï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹ç¼–ç 
            encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']
            df = None

            for encoding in encodings:
                try:
                    df = pd.read_csv(self.file_path, encoding=encoding)
                    print(f"ä½¿ç”¨ç¼–ç : {encoding}")
                    break
                except UnicodeDecodeError:
                    continue

            if df is None:
                raise ValueError("æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç ï¼Œè¯·å°è¯•UTF-8æˆ–GBKç¼–ç ")

            self.stats['total_rows'] = len(df)
            print(f"æ€»è¡Œæ•°: {self.stats['total_rows']}")

            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            missing_fields = []
            for field in self.REQUIRED_FIELDS.keys():
                if field not in df.columns:
                    missing_fields.append(field)

            if missing_fields:
                print(f"è­¦å‘Š: ç¼ºå°‘ä»¥ä¸‹å­—æ®µ: {missing_fields}")
                print(f"å¯ç”¨å­—æ®µ: {list(df.columns)}")

            # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
            print("\nå‰3è¡Œæ•°æ®é¢„è§ˆ:")
            print(df.head(3).to_string())

            # åŸºæœ¬æ•°æ®ç»Ÿè®¡
            print(f"\nåˆçº¦ä»£ç åˆ†å¸ƒ:")
            if 'åˆçº¦ä»£ç ' in df.columns:
                symbol_counts = df['åˆçº¦ä»£ç '].value_counts().head(10)
                for symbol, count in symbol_counts.items():
                    print(f"  {symbol}: {count} è¡Œ")

            return df

        except Exception as e:
            print(f"åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {e}")
            raise

    def import_data(self, batch_size: int = 10000, skip_existing: bool = True) -> Dict:
        """
        ä¿®å¤ç‰ˆï¼šæŒ‰åˆçº¦åˆ†ç»„åå†åˆ†æ‰¹å¯¼å…¥æ•°æ®
        """
        print(f"\nå¼€å§‹å¯¼å…¥æ•°æ®...")
        print(f"æ‰¹å¤„ç†å¤§å°: {batch_size}")
        print(f"è·³è¿‡å·²å­˜åœ¨æ•°æ®: {skip_existing}")

        # 1. åŠ è½½CSV
        df = self.load_and_validate_csv()

        if 'åˆçº¦ä»£ç ' not in df.columns:
            raise ValueError("CSVæ–‡ä»¶å¿…é¡»åŒ…å«'åˆçº¦ä»£ç 'åˆ—")

        # 2. æŒ‰åˆçº¦åˆ†ç»„è§£æBaræ•°æ®
        contract_bars: Dict[str, List[BarData]] = {}

        print(f"\nè§£ææ•°æ®å¹¶åˆ†ç»„...")
        for idx, row in df.iterrows():
            # æ˜¾ç¤ºè¿›åº¦
            if idx % 10000 == 0 and idx > 0:
                print(f"  å·²è§£æ {idx} è¡Œ...")

            bar = self.parse_row_to_bar(row, idx)
            if bar:
                # æŒ‰symbolåˆ†ç»„
                if bar.symbol not in contract_bars:
                    contract_bars[bar.symbol] = []
                contract_bars[bar.symbol].append(bar)

        print(f"è§£æå®Œæˆï¼Œå…± {len(contract_bars)} ä¸ªåˆçº¦")

        # 3. å¯¹æ¯ä¸ªåˆçº¦å•ç‹¬å¤„ç†
        total_saved = 0

        for symbol, bars in contract_bars.items():
            print(f"\nå¤„ç†åˆçº¦: {symbol}")
            print(f"  åŸå§‹Baræ•°: {len(bars)}")

            # æŒ‰æ—¶é—´æ’åº
            bars.sort(key=lambda x: x.datetime)

            # å»é‡ï¼ˆç›¸åŒdatetimeçš„Barï¼‰
            unique_bars = []
            seen_times = set()

            for bar in bars:
                if bar.datetime not in seen_times:
                    seen_times.add(bar.datetime)
                    unique_bars.append(bar)

            if len(unique_bars) < len(bars):
                print(f"  å»é‡å: {len(unique_bars)} æ¡ï¼ˆç§»é™¤ {len(bars) - len(unique_bars)} æ¡é‡å¤ï¼‰")

            bars = unique_bars

            # è·³è¿‡å·²å­˜åœ¨æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if skip_existing and bars:
                # æŸ¥è¯¢è¯¥åˆçº¦çš„ç°æœ‰æ•°æ®æ—¶é—´èŒƒå›´
                existing_bars = self.database.load_bar_data(
                    symbol=symbol,
                    exchange=self.exchange,
                    interval=self.interval,
                    start=bars[0].datetime,
                    end=bars[-1].datetime
                )

                if existing_bars:
                    existing_times = {b.datetime for b in existing_bars}
                    new_bars = [b for b in bars if b.datetime not in existing_times]
                    print(f"  å·²å­˜åœ¨: {len(existing_bars)} æ¡ï¼Œæ–°å¢: {len(new_bars)} æ¡")
                    bars = new_bars

            if not bars:
                print(f"  âš ï¸  æ²¡æœ‰éœ€è¦å¯¼å…¥çš„æ–°æ•°æ®")
                continue

            # 4. æŒ‰åˆçº¦åˆ†æ‰¹ä¿å­˜
            print(f"  å‡†å¤‡ä¿å­˜ {len(bars)} æ¡Baræ•°æ®...")
            contract_saved = 0

            for i in range(0, len(bars), batch_size):
                batch = bars[i:i + batch_size]

                try:
                    # âœ… å…³é”®ä¿®å¤ï¼šæ¯ä¸ªæ‰¹æ¬¡åªåŒ…å«åŒä¸€ä¸ªåˆçº¦çš„æ•°æ®
                    self.database.save_bar_data(batch)
                    contract_saved += len(batch)

                    if (i // batch_size) % 10 == 0:  # æ¯10æ‰¹æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                        print(f"    æ‰¹æ¬¡ {i // batch_size + 1}: å·²ä¿å­˜ {min(i + batch_size, len(bars))}/{len(bars)}")

                except Exception as e:
                    print(f"    âŒ æ‰¹æ¬¡ {i // batch_size + 1} ä¿å­˜å¤±è´¥: {e}")
                    # å°è¯•é€æ¡ä¿å­˜ä»¥æ‰¾å‡ºé—®é¢˜Bar
                    for j, bar in enumerate(batch):
                        try:
                            self.database.save_bar_data([bar])
                            contract_saved += 1
                        except Exception as single_error:
                            print(f"      è¡Œ {i + j} å¤±è´¥: {single_error}")
                            print(f"      å¤±è´¥Bar: {bar.symbol} {bar.datetime} {bar.close_price}")

            total_saved += contract_saved
            print(f"  âœ… åˆçº¦ {symbol} ä¿å­˜å®Œæˆ: {contract_saved} æ¡")

            # éªŒè¯ä¿å­˜çš„æ•°æ®
            # self._verify_saved_data(symbol, contract_saved)

        # 5. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.stats['saved_bars'] = total_saved
        self.stats['unique_symbols'] = set(contract_bars.keys())

        print(f"\nâœ… æ•°æ®å¯¼å…¥å®Œæˆ")
        print(f"   æ€»ä¿å­˜Baræ•°: {total_saved} æ¡")
        print(f"   æ¶‰åŠåˆçº¦æ•°: {len(contract_bars)} ä¸ª")

        self.print_statistics()

        return self.stats

    def _verify_saved_data(self, symbol: str, expected_count: int):
        """éªŒè¯ä¿å­˜çš„æ•°æ®"""
        try:
            # æŸ¥è¯¢åˆšåˆšä¿å­˜çš„æ•°æ®
            saved_bars = self.database.load_bar_data(
                symbol=symbol,
                exchange=self.exchange,
                interval=self.interval,
                limit=min(5, expected_count)
            )

            if saved_bars:
                print(f"    éªŒè¯: æ•°æ®åº“ä¸­æœ‰ {len(saved_bars)} æ¡ {symbol} æ•°æ®")
                if expected_count > 0 and len(saved_bars) < min(5, expected_count):
                    print(f"    âš ï¸  é¢„æœŸè‡³å°‘ {min(5, expected_count)} æ¡ï¼Œå®é™… {len(saved_bars)} æ¡")
            else:
                print(f"    âš ï¸  éªŒè¯å¤±è´¥: æœªæ‰¾åˆ° {symbol} çš„æ•°æ®")

        except Exception as e:
            print(f"    éªŒè¯é”™è¯¯: {e}")


        # 4. æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self.print_statistics()

        return self.stats

    def print_statistics(self):
        """æ‰“å°å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ“Š å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)

        print(f"æ–‡ä»¶è·¯å¾„: {self.file_path}")
        print(f"æ€»è¡Œæ•°: {self.stats['total_rows']}")
        print(f"æœ‰æ•ˆè¡Œæ•°: {self.stats['valid_rows']}")
        print(f"æ— æ•ˆè¡Œæ•°: {self.stats['invalid_rows']}")

        if self.stats['unique_symbols']:
            print(f"åˆçº¦æ•°é‡: {len(self.stats['unique_symbols'])}")
            print(f"åˆçº¦åˆ—è¡¨: {sorted(self.stats['unique_symbols'])}")

        if self.stats['time_range']['start'] and self.stats['time_range']['end']:
            print(f"æ—¶é—´èŒƒå›´: {self.stats['time_range']['start']} åˆ° {self.stats['time_range']['end']}")

        print(f"ä¿å­˜Baræ•°: {self.stats['saved_bars']}")
        print("=" * 60)

    def verify_import(self, sample_symbol: str = None) -> List[BarData]:
        """
        éªŒè¯å¯¼å…¥çš„æ•°æ®

        Args:
            sample_symbol: ç¤ºä¾‹åˆçº¦ä»£ç ï¼Œç”¨äºéªŒè¯

        Returns:
            æŸ¥è¯¢åˆ°çš„Baræ•°æ®
        """
        print(f"\nğŸ” éªŒè¯å¯¼å…¥çš„æ•°æ®...")

        if not self.stats['unique_symbols']:
            print("æ²¡æœ‰å¯éªŒè¯çš„åˆçº¦")
            return []

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªåˆçº¦æˆ–æŒ‡å®šåˆçº¦è¿›è¡ŒéªŒè¯
        if sample_symbol and sample_symbol in self.stats['unique_symbols']:
            verify_symbol = sample_symbol
        else:
            verify_symbol = next(iter(self.stats['unique_symbols']))

        # æŸ¥è¯¢æ•°æ®åº“
        bars = self.database.load_bar_data(
            symbol=verify_symbol,
            exchange=self.exchange,
            interval=self.interval,
            start=self.stats['time_range']['start'],
            end=self.stats['time_range']['end'],
            limit=5
        )

        if bars:
            print(f"åˆçº¦ {verify_symbol} çš„æ•°æ®éªŒè¯æˆåŠŸ:")
            for i, bar in enumerate(bars):
                print(f"  {i + 1}. {bar.datetime}: "
                      f"O:{bar.open_price:.2f} H:{bar.high_price:.2f} "
                      f"L:{bar.low_price:.2f} C:{bar.close_price:.2f} "
                      f"V:{bar.volume}")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°åˆçº¦ {verify_symbol} çš„æ•°æ®")

        return bars


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    import sys

    parser = argparse.ArgumentParser(description='å¯¼å…¥CFFEXå¤šåˆçº¦åˆ†é’ŸBaræ•°æ®åˆ°vn.pyæ•°æ®åº“')
    parser.add_argument('--file', type=str, required=True, help='CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch-size', type=int, default=10000, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--no-skip', action='store_true', help='ä¸è·³è¿‡å·²å­˜åœ¨çš„æ•°æ®ï¼ˆé»˜è®¤è·³è¿‡ï¼‰')
    parser.add_argument('--verify', action='store_true', help='å¯¼å…¥åéªŒè¯æ•°æ®')

    args = parser.parse_args()

    try:
        # åˆ›å»ºå¯¼å…¥å™¨
        importer = CFFEXMinuteBarImporter(args.file)

        # å¯¼å…¥æ•°æ®
        stats = importer.import_data(
            batch_size=args.batch_size,
            skip_existing=not args.no_skip
        )

        # éªŒè¯æ•°æ®ï¼ˆå¯é€‰ï¼‰
        if args.verify and stats['saved_bars'] > 0:
            importer.verify_import()

        print(f"\nğŸ‰ å¯¼å…¥å®Œæˆ!")

    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•:
    # python import_cffex_minute_bars_v4.py --file your_data.csv
    # python import_cffex_minute_bars_v4.py --file your_data.csv --batch-size 5000 --verify
    # python import_cffex_minute_bars_v4.py --file your_data.csv --no-skip

    main()