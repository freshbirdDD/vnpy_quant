"""
import_cffex_tick_data_fixed.py
vn.py 4.2ç‰ˆæœ¬ - å°†åŒ…å«å¤šä¸ªCFFEXåˆçº¦çš„Tickæ•°æ®CSVå¯¼å…¥æ•°æ®åº“

ä¿®å¤ç‰ˆï¼šæ­£ç¡®ä½¿ç”¨TICK_FIELDSæ˜ å°„å…³ç³»
"""
import pandas as pd
import numpy as np
from datetime import datetime, time
from pathlib import Path
from typing import List, Dict, Set, Optional, Tuple
from vnpy.trader.constant import Exchange, Direction, Offset
from vnpy.trader.object import TickData
from vnpy.trader.database import BaseDatabase, get_database


class CFFEXTickDataImporterFixed:
    """CFFEXäº¤æ˜“æ‰€å¤šåˆçº¦Tickæ•°æ®å¯¼å…¥å™¨ (ä¿®å¤ç‰ˆ)"""

    # CSVåˆ—ååˆ°TickDataå±æ€§åçš„æ˜ å°„
    TICK_FIELDS = {
        # å¿…éœ€å­—æ®µ
        'UpdateTime': 'datetime',           # æ˜ å°„åˆ°TickData.datetime (éœ€è¦è½¬æ¢ä¸ºdatetimeå¯¹è±¡)
        'InstrumentID': 'symbol',           # æ˜ å°„åˆ°TickData.symbol

        # ä»·æ ¼å’Œæˆäº¤é‡å­—æ®µ
        'LastPrice': 'last_price',
        'Volume': 'volume',
        'Turnover': 'turnover',
        'OpenInterest': 'open_interest',

        # ä¹°å–ç›˜å£å­—æ®µ
        'BidPrice1': 'bid_price_1',
        'BidVolume1': 'bid_volume_1',
        'AskPrice1': 'ask_price_1',
        'AskVolume1': 'ask_volume_1',

        # å…¶ä»–ä»·æ ¼æ¡£ä½
        'BidPrice2': 'bid_price_2',
        'BidVolume2': 'bid_volume_2',
        'AskPrice2': 'ask_price_2',
        'AskVolume2': 'ask_volume_2',

        'BidPrice3': 'bid_price_3',
        'BidVolume3': 'bid_volume_3',
        'AskPrice3': 'ask_price_3',
        'AskVolume3': 'ask_volume_3',

        'BidPrice4': 'bid_price_4',
        'BidVolume4': 'bid_volume_4',
        'AskPrice4': 'ask_price_4',
        'AskVolume4': 'ask_volume_4',

        'BidPrice5': 'bid_price_5',
        'BidVolume5': 'bid_volume_5',
        'AskPrice5': 'ask_price_5',
        'AskVolume5': 'ask_volume_5',

        # å…¶ä»–ä»·æ ¼å­—æ®µ
        'UpperLimitPrice': 'limit_up',
        'LowerLimitPrice': 'limit_down',
        'PreClosePrice': 'pre_close',
        # ToDo æš‚æ—¶å…ˆæ³¨é‡Šæ‰ï¼ŒDB tick dataé‡Œæ²¡æœ‰è¿™ä¸ªå­—æ®µ
        # 'PreSettlementPrice': 'pre_settlement',
        'OpenPrice': 'open_price',
        'HighPrice': 'high_price',
        'LowPrice': 'low_price',
        'SettlementPrice': 'settlement_price',
    }

    def __init__(self, file_path: str, custom_field_mapping: Dict[str, str] = None):
        """
        åˆå§‹åŒ–å¯¼å…¥å™¨

        Args:
            file_path: CSVæ–‡ä»¶è·¯å¾„
            custom_field_mapping: è‡ªå®šä¹‰å­—æ®µæ˜ å°„ï¼Œç”¨äºè¦†ç›–é»˜è®¤æ˜ å°„
        """
        self.file_path = Path(file_path)
        if not self.file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")

        self.exchange = Exchange.CFFEX
        self.gateway_name = "TICK_CSV_IMPORT"
        self.database: BaseDatabase = get_database()

        # æ›´æ–°å­—æ®µæ˜ å°„ï¼ˆå¦‚æœæä¾›äº†è‡ªå®šä¹‰æ˜ å°„ï¼‰
        if custom_field_mapping:
            self.TICK_FIELDS.update(custom_field_mapping)

        # åˆ›å»ºåå‘æ˜ å°„ï¼šTickDataå±æ€§å -> CSVåˆ—å
        self.reverse_mapping = {v: k for k, v in self.TICK_FIELDS.items()}

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_rows': 0,
            'valid_rows': 0,
            'invalid_rows': 0,
            'unique_symbols': set(),
            'time_range': {'start': None, 'end': None},
            'saved_ticks': 0,
            'missing_bid_ask': 0,
            'missing_last_price': 0,
            'field_mapping_used': self.TICK_FIELDS.copy()
        }

    def parse_datetime(self, dt_str: str) -> Optional[datetime]:
        """
        è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡
        """
        if pd.isna(dt_str) or not isinstance(dt_str, str):
            return None

        dt_str = str(dt_str).strip()
        if not dt_str:
            return None

        # å°è¯•å¤šç§æ—¶é—´æ ¼å¼
        date_formats = [
            '%Y-%m-%d %H:%M:%S.%f',
            '%Y/%m/%d %H:%M:%S.%f',
            '%Y%m%d %H:%M:%S.%f',
            '%Y-%m-%d %H:%M:%S',
            '%Y/%m/%d %H:%M:%S',
            '%Y%m%d %H:%M:%S',
            '%Y-%m-%d %H:%M',
            '%Y/%m/%d %H:%M',
            '%Y%m%d %H:%M',
        ]

        for fmt in date_formats:
            try:
                return datetime.strptime(dt_str, fmt)
            except ValueError:
                continue

        # å¦‚æœéƒ½ä¸æˆåŠŸï¼Œå°è¯•åªè§£ææ—¥æœŸéƒ¨åˆ†
        try:
            date_part = dt_str.split()[0]
            dt = datetime.strptime(date_part, '%Y-%m-%d')
            return dt.replace(hour=9, minute=30, second=0, microsecond=0)
        except:
            return None

    def validate_symbol(self, symbol: str) -> Optional[str]:
        """
        éªŒè¯å¹¶æ¸…ç†åˆçº¦ä»£ç 
        """
        if pd.isna(symbol) or not isinstance(symbol, str):
            return None

        symbol = str(symbol).strip().upper()

        # ç§»é™¤å¯èƒ½åŒ…å«çš„äº¤æ˜“æ‰€åç¼€
        if '.' in symbol:
            parts = symbol.split('.')
            symbol = parts[0]  # å–ç¬¬ä¸€ä¸ªéƒ¨åˆ†ä½œä¸ºåˆçº¦ä»£ç 

        # éªŒè¯åŸºæœ¬æ ¼å¼ï¼ˆè‡³å°‘2ä¸ªå­—æ¯+æ•°å­—ï¼‰
        if len(symbol) >= 2 and symbol[:2].isalpha():
            return symbol
        return None

    def get_csv_column_name(self, tick_attribute: str) -> Optional[str]:
        """
        æ ¹æ®TickDataå±æ€§åè·å–CSVåˆ—å

        Args:
            tick_attribute: TickDataå±æ€§åï¼Œå¦‚ 'last_price', 'volume' ç­‰

        Returns:
            CSVåˆ—åï¼Œå¦‚æœæœªæ‰¾åˆ°æ˜ å°„åˆ™è¿”å›None
        """
        return self.reverse_mapping.get(tick_attribute)

    def parse_row_to_tick(self, row: pd.Series, index: int) -> Optional[TickData]:
        """
        å°†ä¸€è¡Œæ•°æ®è§£æä¸ºTickDataå¯¹è±¡ï¼Œä½¿ç”¨TICK_FIELDSæ˜ å°„å…³ç³»
        """
        try:
            # 1. è·å–åˆçº¦ä»£ç å’Œæ—¶é—´ï¼ˆå¿…éœ€å­—æ®µï¼‰
            symbol_csv_col = self.get_csv_column_name('symbol')
            datetime_csv_col = self.get_csv_column_name('datetime')

            if not symbol_csv_col or not datetime_csv_col:
                print(f"è¡Œ {index}: ç¼ºå°‘å¿…è¦çš„å­—æ®µæ˜ å°„ (symbolæˆ–datetime)")
                return None

            # 2. è§£æåˆçº¦ä»£ç 
            raw_symbol = row.get(symbol_csv_col)
            symbol = self.validate_symbol(raw_symbol)
            if not symbol:
                print(f"è¡Œ {index}: æ— æ•ˆçš„åˆçº¦ä»£ç  '{raw_symbol}'")
                return None

            # 3. è§£ææ—¶é—´
            raw_time = row.get(datetime_csv_col)
            dt = self.parse_datetime(raw_time)
            if not dt:
                print(f"è¡Œ {index}: æ— æ•ˆçš„æ—¶é—´æ ¼å¼ '{raw_time}'")
                return None

            # 4. åˆ›å»ºTickDataå¯¹è±¡
            tick = TickData(
                gateway_name=self.gateway_name,
                symbol=symbol,
                exchange=self.exchange,
                datetime=dt,
                name="",  # å¯é€‰çš„åˆçº¦åç§°
            )

            # 5. ä½¿ç”¨æ˜ å°„å…³ç³»è®¾ç½®æ‰€æœ‰å­—æ®µ
            for csv_col, tick_attr in self.TICK_FIELDS.items():
                # è·³è¿‡å·²ç»å¤„ç†çš„å­—æ®µ
                if tick_attr in ['symbol', 'datetime']:
                    continue

                # æ£€æŸ¥CSVä¸­æ˜¯å¦æœ‰è¯¥åˆ—
                if csv_col not in row:
                    continue

                value = row[csv_col]

                # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆå€¼
                if pd.isna(value) or (isinstance(value, (int, float)) and value == 0):
                    continue

                try:
                    # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼ˆä»·æ ¼å’Œæˆäº¤é‡å­—æ®µï¼‰
                    float_value = float(value)
                    setattr(tick, tick_attr, float_value)
                except (ValueError, TypeError):
                    # å¦‚æœä¸æ˜¯æ•°å€¼ï¼Œè·³è¿‡ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹ï¼‰
                    pass

            # 6. æ£€æŸ¥å¿…éœ€çš„ä»·æ ¼å­—æ®µ
            last_price_csv_col = self.get_csv_column_name('last_price')
            if last_price_csv_col and last_price_csv_col in row:
                try:
                    tick.last_price = float(row[last_price_csv_col])
                except:
                    self.stats['missing_last_price'] += 1

            # å¦‚æœæœ€æ–°ä»·ç¼ºå¤±ï¼Œå°è¯•ä»ä¹°å–ä»·æ¨ç®—
            if not tick.last_price or tick.last_price == 0:
                if tick.bid_price_1 and tick.bid_price_1 > 0:
                    tick.last_price = tick.bid_price_1
                elif tick.ask_price_1 and tick.ask_price_1 > 0:
                    tick.last_price = tick.ask_price_1
                else:
                    print(f"è¡Œ {index}: ç¼ºå°‘ä»·æ ¼ä¿¡æ¯")
                    self.stats['invalid_rows'] += 1
                    return None

            # 7. ç¡®ä¿ä¹°å–ç›˜å£æœ‰æœ‰æ•ˆå€¼
            if not tick.bid_price_1 or tick.bid_price_1 == 0:
                tick.bid_price_1 = tick.last_price
                self.stats['missing_bid_ask'] += 1

            if not tick.ask_price_1 or tick.ask_price_1 == 0:
                tick.ask_price_1 = tick.last_price
                self.stats['missing_bid_ask'] += 1

            if not tick.bid_volume_1 or tick.bid_volume_1 == 0:
                tick.bid_volume_1 = 1

            if not tick.ask_volume_1 or tick.ask_volume_1 == 0:
                tick.ask_volume_1 = 1

            # 8. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats['valid_rows'] += 1
            self.stats['unique_symbols'].add(symbol)

            if not self.stats['time_range']['start'] or dt < self.stats['time_range']['start']:
                self.stats['time_range']['start'] = dt
            if not self.stats['time_range']['end'] or dt > self.stats['time_range']['end']:
                self.stats['time_range']['end'] = dt

            return tick

        except Exception as e:
            print(f"è¡Œ {index}: è§£æTickæ•°æ®é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            self.stats['invalid_rows'] += 1
            return None

    def detect_csv_fields(self, df: pd.DataFrame) -> Dict[str, str]:
        """
        è‡ªåŠ¨æ£€æµ‹CSVå­—æ®µå¹¶å°è¯•åŒ¹é…æ˜ å°„

        Args:
            df: DataFrameå¯¹è±¡

        Returns:
            æ£€æµ‹åˆ°çš„å­—æ®µæ˜ å°„
        """
        detected_mapping = {}
        available_columns = list(df.columns)

        print(f"CSVå¯ç”¨åˆ—: {available_columns}")

        # å¸¸è§çš„ä¸­æ–‡å­—æ®µåæ˜ å°„ï¼ˆå¦‚æœCSVä½¿ç”¨ä¸­æ–‡åˆ—åï¼‰
        chinese_mapping = {
            'æ—¶é—´': 'UpdateTime',
            'åˆçº¦ä»£ç ': 'InstrumentID',
            'æœ€æ–°ä»·': 'LastPrice',
            'æˆäº¤é‡': 'Volume',
            'æˆäº¤é¢': 'Turnover',
            'æŒä»“é‡': 'OpenInterest',
            'ä¹°ä¸€ä»·': 'BidPrice1',
            'ä¹°ä¸€é‡': 'BidVolume1',
            'å–ä¸€ä»·': 'AskPrice1',
            'å–ä¸€é‡': 'AskVolume1',
            'æ¶¨åœä»·': 'UpperLimitPrice',
            'è·Œåœä»·': 'LowerLimitPrice',
            'æ˜¨æ”¶': 'PreClosePrice',
            'æ˜¨ç»“': 'PreSettlementPrice',
            'å¼€ç›˜ä»·': 'OpenPrice',
            'æœ€é«˜ä»·': 'HighPrice',
            'æœ€ä½ä»·': 'LowPrice',
            'ç»“ç®—ä»·': 'SettlementPrice',
        }

        # é¦–å…ˆå°è¯•ä¸­æ–‡æ˜ å°„
        for csv_col in available_columns:
            if csv_col in chinese_mapping:
                standard_col = chinese_mapping[csv_col]
                if standard_col in self.TICK_FIELDS:
                    detected_mapping[standard_col] = self.TICK_FIELDS[standard_col]
                    print(f"  æ£€æµ‹åˆ°æ˜ å°„: '{csv_col}' -> {standard_col} -> {self.TICK_FIELDS[standard_col]}")

        # ç„¶åå°è¯•ç›´æ¥åŒ¹é…æ ‡å‡†åˆ—å
        for csv_col in available_columns:
            if csv_col in self.TICK_FIELDS:
                detected_mapping[csv_col] = self.TICK_FIELDS[csv_col]
                print(f"  ç›´æ¥åŒ¹é…: '{csv_col}' -> {self.TICK_FIELDS[csv_col]}")

        return detected_mapping

    def load_and_validate_csv(self) -> pd.DataFrame:
        """
        åŠ è½½CSVæ–‡ä»¶å¹¶è¿›è¡ŒåŸºæœ¬éªŒè¯
        """
        print(f"åŠ è½½CSVæ–‡ä»¶: {self.file_path}")

        try:
            # è¯»å–CSVï¼Œå°è¯•è‡ªåŠ¨æ£€æµ‹ç¼–ç 
            encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']
            df = None

            for encoding in encodings:
                try:
                    df = pd.read_csv(self.file_path, encoding=encoding)
                    print(f"ä½¿ç”¨ç¼–ç : {encoding}")
                    break
                except UnicodeDecodeError:
                    continue

            if df is None:
                raise ValueError("æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç ï¼Œè¯·å°è¯•UTF-8æˆ–GBKç¼–ç ")

            self.stats['total_rows'] = len(df)
            print(f"æ€»è¡Œæ•°: {self.stats['total_rows']}")

            # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
            print("\nå‰3è¡Œæ•°æ®é¢„è§ˆ:")
            print(df.head(3).to_string())

            # æ˜¾ç¤ºåˆ—ä¿¡æ¯
            print(f"\nCSVåˆ—ä¿¡æ¯:")
            for i, col in enumerate(df.columns):
                sample_value = df[col].iloc[0] if len(df) > 0 else 'N/A'
                print(f"  {i+1:2d}. {col:20s} (ç¤ºä¾‹: {str(sample_value)[:30]}...)")

            # è‡ªåŠ¨æ£€æµ‹å­—æ®µæ˜ å°„
            print(f"\nğŸ” è‡ªåŠ¨æ£€æµ‹å­—æ®µæ˜ å°„...")
            detected_mapping = self.detect_csv_fields(df)

            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_mappings = ['symbol', 'datetime', 'last_price']
            missing_required = []

            for req_attr in required_mappings:
                csv_col = self.get_csv_column_name(req_attr)
                if not csv_col or csv_col not in df.columns:
                    missing_required.append(req_attr)

            if missing_required:
                print(f"âš ï¸  è­¦å‘Š: ç¼ºå°‘ä»¥ä¸‹å¿…éœ€å­—æ®µçš„æ˜ å°„: {missing_required}")
                print("   è¯·æ£€æŸ¥CSVæ–‡ä»¶åˆ—åæˆ–æä¾›è‡ªå®šä¹‰å­—æ®µæ˜ å°„")

                # å°è¯•ä»æ£€æµ‹åˆ°çš„æ˜ å°„ä¸­æŸ¥æ‰¾
                for req_attr in missing_required:
                    for csv_col, tick_attr in self.TICK_FIELDS.items():
                        if tick_attr == req_attr and csv_col in df.columns:
                            print(f"   æ‰¾åˆ°æ›¿ä»£: '{csv_col}' ä½œä¸º {req_attr}")
                            break

            return df

        except Exception as e:
            print(f"åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {e}")
            raise

    def check_duplicate_ticks(self, symbol: str, ticks: List[TickData]) -> List[TickData]:
        """
        æ£€æŸ¥å¹¶ç§»é™¤é‡å¤çš„Tickæ•°æ®ï¼ˆç›¸åŒsymbolå’Œdatetimeï¼‰
        """
        if not ticks:
            return ticks

        # æŒ‰æ—¶é—´æ’åº
        ticks.sort(key=lambda x: x.datetime)

        # å»é‡
        unique_ticks = []
        seen_datetimes = set()

        for tick in ticks:
            key = (tick.symbol, tick.datetime)
            if key not in seen_datetimes:
                seen_datetimes.add(key)
                unique_ticks.append(tick)

        removed = len(ticks) - len(unique_ticks)
        if removed > 0:
            print(f"  ç§»é™¤ {removed} æ¡é‡å¤Tickæ•°æ®")

        return unique_ticks

    def import_data(self, batch_size: int = 10000, skip_existing: bool = True) -> Dict:
        """
        å¯¼å…¥Tickæ•°æ®
        """
        print(f"\nå¼€å§‹å¯¼å…¥Tickæ•°æ®...")
        print(f"æ‰¹å¤„ç†å¤§å°: {batch_size}")
        print(f"è·³è¿‡å·²å­˜åœ¨æ•°æ®: {skip_existing}")
        print(f"ä½¿ç”¨çš„å­—æ®µæ˜ å°„: {self.TICK_FIELDS}")

        # 1. åŠ è½½CSV
        df = self.load_and_validate_csv()

        # æ£€æŸ¥å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨
        symbol_csv_col = self.get_csv_column_name('symbol')
        datetime_csv_col = self.get_csv_column_name('datetime')

        if not symbol_csv_col or symbol_csv_col not in df.columns:
            raise ValueError(f"CSVæ–‡ä»¶å¿…é¡»åŒ…å«åˆçº¦ä»£ç åˆ—ï¼Œæ˜ å°„ä¸º: {self.get_csv_column_name('symbol')}")

        if not datetime_csv_col or datetime_csv_col not in df.columns:
            raise ValueError(f"CSVæ–‡ä»¶å¿…é¡»åŒ…å«æ—¶é—´åˆ—ï¼Œæ˜ å°„ä¸º: {self.get_csv_column_name('datetime')}")

        # 2. æŒ‰åˆçº¦åˆ†ç»„è§£æTickæ•°æ®
        contract_ticks: Dict[str, List[TickData]] = {}

        print(f"\nè§£ææ•°æ®å¹¶åˆ†ç»„...")
        for idx, row in df.iterrows():
            # æ˜¾ç¤ºè¿›åº¦
            if idx % 10000 == 0 and idx > 0:
                print(f"  å·²è§£æ {idx} è¡Œ...")

            tick = self.parse_row_to_tick(row, idx)
            if tick:
                # æŒ‰symbolåˆ†ç»„
                if tick.symbol not in contract_ticks:
                    contract_ticks[tick.symbol] = []
                contract_ticks[tick.symbol].append(tick)

        print(f"è§£æå®Œæˆï¼Œå…± {len(contract_ticks)} ä¸ªåˆçº¦")

        # 3. å¯¹æ¯ä¸ªåˆçº¦å•ç‹¬å¤„ç†
        total_saved = 0

        for symbol, ticks in contract_ticks.items():
            print(f"\nå¤„ç†åˆçº¦: {symbol}")
            print(f"  åŸå§‹Tickæ•°: {len(ticks)}")

            # å»é‡
            ticks = self.check_duplicate_ticks(symbol, ticks)

            if not ticks:
                print(f"  âš ï¸  æ²¡æœ‰æœ‰æ•ˆTickæ•°æ®")
                continue

            # è·³è¿‡å·²å­˜åœ¨æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            # æ³¨æ„ï¼šTickæ•°æ®å»é‡é€šå¸¸ç”±æ•°æ®åº“çš„å”¯ä¸€çº¦æŸå¤„ç†

            # 4. åˆ†æ‰¹ä¿å­˜
            print(f"  å‡†å¤‡ä¿å­˜ {len(ticks)} æ¡Tickæ•°æ®...")
            contract_saved = 0

            for i in range(0, len(ticks), batch_size):
                batch = ticks[i:i + batch_size]

                try:
                    # ä¿å­˜Tickæ•°æ®
                    self.database.save_tick_data(batch)
                    contract_saved += len(batch)

                    if (i // batch_size) % 10 == 0 and (i // batch_size) > 0:
                        print(f"    æ‰¹æ¬¡ {i // batch_size + 1}: å·²ä¿å­˜ {min(i + batch_size, len(ticks))}/{len(ticks)}")

                except Exception as e:
                    print(f"    âŒ æ‰¹æ¬¡ {i // batch_size + 1} ä¿å­˜å¤±è´¥: {e}")
                    # å°è¯•é€æ¡ä¿å­˜ä»¥æ‰¾å‡ºé—®é¢˜Tick
                    error_count = 0
                    for j, tick in enumerate(batch):
                        try:
                            self.database.save_tick_data([tick])
                            contract_saved += 1
                        except Exception as single_error:
                            error_count += 1
                            if error_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                                print(f"      è¡Œ {i + j} å¤±è´¥: {single_error}")
                                print(f"      å¤±è´¥Tick: {tick.symbol} {tick.datetime} {tick.last_price}")

                    if error_count > 5:
                        print(f"      è¿˜æœ‰ {error_count - 5} ä¸ªé”™è¯¯æœªæ˜¾ç¤º...")

            total_saved += contract_saved
            print(f"  âœ… åˆçº¦ {symbol} ä¿å­˜å®Œæˆ: {contract_saved} æ¡")

        # 5. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.stats['saved_ticks'] = total_saved
        self.stats['unique_symbols'] = set(contract_ticks.keys())

        print(f"\nâœ… Tickæ•°æ®å¯¼å…¥å®Œæˆ")
        print(f"   æ€»ä¿å­˜Tickæ•°: {total_saved} æ¡")
        print(f"   æ¶‰åŠåˆçº¦æ•°: {len(contract_ticks)} ä¸ª")

        self.print_statistics()

        return self.stats

    def print_statistics(self):
        """æ‰“å°å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ“Š Tickæ•°æ®å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)

        print(f"æ–‡ä»¶è·¯å¾„: {self.file_path}")
        print(f"æ€»è¡Œæ•°: {self.stats['total_rows']}")
        print(f"æœ‰æ•ˆTickæ•°: {self.stats['valid_rows']}")
        print(f"æ— æ•ˆè¡Œæ•°: {self.stats['invalid_rows']}")
        print(f"ç¼ºå°‘ä¹°å–ç›˜å£æ•°: {self.stats['missing_bid_ask']}")
        print(f"ç¼ºå°‘æœ€æ–°ä»·æ•°: {self.stats['missing_last_price']}")

        if self.stats['unique_symbols']:
            print(f"åˆçº¦æ•°é‡: {len(self.stats['unique_symbols'])}")
            print(f"åˆçº¦åˆ—è¡¨: {sorted(self.stats['unique_symbols'])}")

        if self.stats['time_range']['start'] and self.stats['time_range']['end']:
            print(f"æ—¶é—´èŒƒå›´: {self.stats['time_range']['start']} åˆ° {self.stats['time_range']['end']}")

        print(f"ä¿å­˜Tickæ•°: {self.stats['saved_ticks']}")

        # æ˜¾ç¤ºä½¿ç”¨çš„å­—æ®µæ˜ å°„
        print(f"\nä½¿ç”¨çš„å­—æ®µæ˜ å°„:")
        for csv_col, tick_attr in self.stats['field_mapping_used'].items():
            print(f"  {csv_col:20s} -> {tick_attr}")

        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    import sys
    import json

    parser = argparse.ArgumentParser(description='å¯¼å…¥CFFEXå¤šåˆçº¦Tickæ•°æ®åˆ°vn.pyæ•°æ®åº“')
    parser.add_argument('--file', type=str, required=True, help='CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch-size', type=int, default=10000, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--no-skip', action='store_true', help='ä¸è·³è¿‡å·²å­˜åœ¨çš„æ•°æ®ï¼ˆé»˜è®¤è·³è¿‡ï¼‰')
    parser.add_argument('--verify', action='store_true', help='å¯¼å…¥åéªŒè¯æ•°æ®')
    parser.add_argument('--mapping-file', type=str, help='è‡ªå®šä¹‰å­—æ®µæ˜ å°„JSONæ–‡ä»¶')

    args = parser.parse_args()

    try:
        # åŠ è½½è‡ªå®šä¹‰å­—æ®µæ˜ å°„ï¼ˆå¦‚æœæœ‰ï¼‰
        custom_mapping = {}
        if args.mapping_file:
            with open(args.mapping_file, 'r', encoding='utf-8') as f:
                custom_mapping = json.load(f)
            print(f"åŠ è½½è‡ªå®šä¹‰å­—æ®µæ˜ å°„: {custom_mapping}")

        # åˆ›å»ºå¯¼å…¥å™¨
        importer = CFFEXTickDataImporterFixed(
            file_path=args.file,
            custom_field_mapping=custom_mapping
        )

        # å¯¼å…¥æ•°æ®
        stats = importer.import_data(
            batch_size=args.batch_size,
            skip_existing=not args.no_skip
        )

        # éªŒè¯æ•°æ®ï¼ˆå¯é€‰ï¼‰
        if args.verify and stats['saved_ticks'] > 0:
            # æŸ¥è¯¢æ•°æ®åº“éªŒè¯
            from vnpy.trader.database import get_database
            database = get_database()

            # æŸ¥è¯¢ç¬¬ä¸€ä¸ªåˆçº¦çš„æ•°æ®ä½œä¸ºéªŒè¯
            if stats['unique_symbols']:
                sample_symbol = list(stats['unique_symbols'])[0]
                try:
                    ticks = database.load_tick_data(
                        symbol=sample_symbol,
                        exchange=importer.exchange,
                        start=stats['time_range']['start'],
                        end=stats['time_range']['end'],
                    )

                    ticks = ticks[:3]

                    if ticks:
                        print(f"\nâœ… éªŒè¯æˆåŠŸ: æŸ¥è¯¢åˆ° {sample_symbol} çš„ {len(ticks)} æ¡Tickæ•°æ®")
                        for i, tick in enumerate(ticks):
                            print(f"  {i+1}. {tick.datetime}: æœ€æ–°ä»·:{tick.last_price:.2f}")
                    else:
                        print(f"âš ï¸  éªŒè¯è­¦å‘Š: æœªæŸ¥è¯¢åˆ° {sample_symbol} çš„æ•°æ®")

                except Exception as e:
                    print(f"âš ï¸  éªŒè¯æ—¶å‡ºé”™: {e}")

        print(f"\nğŸ‰ Tickæ•°æ®å¯¼å…¥å®Œæˆ!")

    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•:
    # python import_cffex_tick_data_fixed.py --file your_tick_data.csv
    # python import_cffex_tick_data_fixed.py --file your_tick_data.csv --batch-size 5000 --verify
    # python import_cffex_tick_data_fixed.py --file your_tick_data.csv --mapping-file custom_mapping.json

    main()